function [output, act_h, act_a] = Forward(W, b, X)
% [OUT, act_h, act_a] = Forward(W, b, X) performs forward propogation on the
% input data 'X' uisng the network defined by weights and biases 'W' and 'b'
% (as generated by InitializeNetwork(..)).
% This function should return the final softmax output layer activations in OUT,
% as well as the hidden layer pre activations in 'act_a', and the hidden layer post
% activations in 'act_h'.
X = X';

%% First Iteration
n = size(W{1,1},1);
Xn = repmat(X,n,1);
act_a{1,1} = dot(W{1,1},Xn,2)+b{1,1};
act_h{1,1} = 1./(1+exp(-act_a{1,1}));

%% Deeper Layers
for i = 2:numel(W)
    n = size(W{1,i},1);
    Xn = repmat(X,n,1);
    act_a{1,i} = dot(W{1,i},act_h{1,i-1},2)+b{1,i};
    act_h{1,i} = 1./(1+exp(-act_a{1,i}));
    if i == numel(W)
        output = act_h{1,i};
    end
end
% exp_nw = exp(nw);
% probabilities = exp_nw/sum(exp_nw);
%     Li = -log10(probabilities);
